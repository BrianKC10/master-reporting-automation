{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aeb1646-89ff-4b43-b337-366be541232c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:41:59.924142Z",
     "iopub.status.busy": "2025-07-17T18:41:59.924046Z",
     "iopub.status.idle": "2025-07-17T18:42:00.979127Z",
     "shell.execute_reply": "2025-07-17T18:42:00.978873Z",
     "shell.execute_reply.started": "2025-07-17T18:41:59.924130Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing and exporting data modules\n",
    "from simple_salesforce import Salesforce\n",
    "import gspread\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "\n",
    "\n",
    "#data manipulation \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef65e2aa-d46d-463f-8269-e200159c98c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:42:00.979612Z",
     "iopub.status.busy": "2025-07-17T18:42:00.979476Z",
     "iopub.status.idle": "2025-07-17T18:42:02.348219Z",
     "shell.execute_reply": "2025-07-17T18:42:02.346521Z",
     "shell.execute_reply.started": "2025-07-17T18:42:00.979603Z"
    }
   },
   "outputs": [],
   "source": [
    "sf = Salesforce(username='bchen@envoy.com',password='TasksandEvents1', security_token='nQWlT8vNdnJwxwtfpS1ic4Z7O')\n",
    "gc = gspread.service_account(filename='/Users/bchen/Downloads/gspread-428120-06947c66447d.json')\n",
    "sht1 = gc.open_by_key('1A6Q8dvoWwLi26tnQQoEo6ZnekvZBQbpgCyP20iQV6Ug')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2545c8d1-0861-4d8b-8f92-70470a13df1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:42:02.355563Z",
     "iopub.status.busy": "2025-07-17T18:42:02.351402Z",
     "iopub.status.idle": "2025-07-17T18:42:09.439749Z",
     "shell.execute_reply": "2025-07-17T18:42:09.439487Z",
     "shell.execute_reply.started": "2025-07-17T18:42:02.355502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/3072986056.py:7: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(StringIO(download_report))\n"
     ]
    }
   ],
   "source": [
    "sf_instance = 'https://envoy.my.salesforce.com/' #Your Salesforce Instance URL\n",
    "reportId = '00OUO000009IZVD2A4' # add report id\n",
    "export = '?isdtp=p1&export=1&enc=UTF-8&xf=csv'\n",
    "sfUrl = sf_instance + reportId + export\n",
    "response = requests.get(sfUrl, headers=sf.headers, cookies={'sid': sf.session_id})\n",
    "download_report = response.content.decode('utf-8')\n",
    "df = pd.read_csv(StringIO(download_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d4eb11-3233-45aa-9c7f-f54d87150ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:42:09.440271Z",
     "iopub.status.busy": "2025-07-17T18:42:09.440198Z",
     "iopub.status.idle": "2025-07-17T18:42:09.493696Z",
     "shell.execute_reply": "2025-07-17T18:42:09.493316Z",
     "shell.execute_reply.started": "2025-07-17T18:42:09.440262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your existing functions:\n",
    "def get_quarter_info(current_date):\n",
    "    fiscal_year = current_date.year if current_date.month >= 2 else current_date.year - 1\n",
    "\n",
    "    if datetime(current_date.year, 2, 1) <= current_date < datetime(current_date.year, 5, 1):\n",
    "        quarter = f\"{fiscal_year + 1}-Q1\"\n",
    "        quarter_start_date = datetime(current_date.year, 2, 1)\n",
    "        quarter_end_date = datetime(current_date.year, 4, 30)\n",
    "    elif datetime(current_date.year, 5, 1) <= current_date < datetime(current_date.year, 8, 1):\n",
    "        quarter = f\"{fiscal_year + 1}-Q2\"\n",
    "        quarter_start_date = datetime(current_date.year, 5, 1)\n",
    "        quarter_end_date = datetime(current_date.year, 7, 31)\n",
    "    elif datetime(current_date.year, 8, 1) <= current_date < datetime(current_date.year, 11, 1):\n",
    "        quarter = f\"{fiscal_year + 1}-Q3\"\n",
    "        quarter_start_date = datetime(current_date.year, 8, 1)\n",
    "        quarter_end_date = datetime(current_date.year, 10, 31)\n",
    "    else:\n",
    "        # Q4: Ends on Jan 31 of the following year\n",
    "        if current_date.month == 1:\n",
    "            quarter = f\"{fiscal_year + 1}-Q4\"\n",
    "            quarter_start_date = datetime(current_date.year - 1, 11, 1)\n",
    "            quarter_end_date = datetime(current_date.year, 1, 31)\n",
    "        else:\n",
    "            quarter = f\"{fiscal_year + 1}-Q4\"\n",
    "            quarter_start_date = datetime(current_date.year, 11, 1)\n",
    "            quarter_end_date = datetime(current_date.year + 1, 1, 31)\n",
    "    return quarter, quarter_start_date, quarter_end_date\n",
    "\n",
    "def compute_week_boundaries_for_quarter(quarter_start_date, quarter_end_date):\n",
    "    total_days = (quarter_end_date - quarter_start_date).days + 1\n",
    "    start_wd = quarter_start_date.weekday()  # Monday=0,...,Sunday=6\n",
    "\n",
    "    # Fixed 11 weeks in the middle: 11*7 = 77 days\n",
    "    leftover = total_days - 77\n",
    "    solutions = []\n",
    "    half = leftover / 2.0\n",
    "\n",
    "    for W1 in range(2, 13):\n",
    "        W13 = leftover - W1\n",
    "        if 4 <= W13 <= 12 and ((start_wd + W1) % 7 == 4):\n",
    "            solutions.append((W1, W13))\n",
    "\n",
    "    if not solutions:\n",
    "        raise ValueError(f\"Could not find a valid week distribution for quarter starting {quarter_start_date}.\")\n",
    "\n",
    "    solutions.sort(key=lambda x: abs(x[0] - half))\n",
    "    best_W1, best_W13 = solutions[0]\n",
    "\n",
    "    week_lengths = [best_W1] + [7]*11 + [best_W13]\n",
    "    week_boundaries = []\n",
    "    start_of_week = quarter_start_date\n",
    "    for length in week_lengths:\n",
    "        end_of_week = start_of_week + timedelta(days=length - 1)\n",
    "        week_boundaries.append((start_of_week, end_of_week))\n",
    "        start_of_week = end_of_week + timedelta(days=1)\n",
    "    return week_boundaries\n",
    "\n",
    "# Helper function to break down a single date\n",
    "def breakdown_date(date_val):\n",
    "    if pd.isnull(date_val):\n",
    "        return pd.Series({\n",
    "            'Quarter': None,\n",
    "            'Week_of_Quarter': None,\n",
    "            'Month': None,\n",
    "            'Day_of_Week': None,\n",
    "            'Day_Name': None\n",
    "        })\n",
    "    # Use your custom logic for quarter and week\n",
    "    quarter, q_start, q_end = get_quarter_info(date_val)\n",
    "    week_boundaries = compute_week_boundaries_for_quarter(q_start, q_end)\n",
    "    week_of_quarter = None\n",
    "    for i, (wstart, wend) in enumerate(week_boundaries):\n",
    "        if wstart <= date_val <= wend:\n",
    "            week_of_quarter = i + 1\n",
    "            break\n",
    "    return pd.Series({\n",
    "        'Quarter': quarter,\n",
    "        'Week_of_Quarter': week_of_quarter,\n",
    "        'Month': date_val.month,\n",
    "        'Day_of_Week': date_val.weekday(),       # Monday=0, Sunday=6\n",
    "        'Day_Name': date_val.strftime(\"%A\")\n",
    "    })\n",
    "\n",
    "\n",
    "def get_last_completed_quarters(n, today=None):\n",
    "    \"\"\"\n",
    "    Returns a list of the last n completed quarters (as strings) based on the custom fiscal calendar.\n",
    "    For example, if today is 03/06/2025 (active quarter = \"2026-Q1\"), the most recent completed quarter is \"2025-Q4\".\n",
    "    \"\"\"\n",
    "    if today is None:\n",
    "        today = datetime.today()\n",
    "    current_quarter, q_start, _ = get_quarter_info(today)\n",
    "    last_date = q_start - timedelta(days=1)\n",
    "    quarters = []\n",
    "    for _ in range(n):\n",
    "        q, q_start, _ = get_quarter_info(last_date)\n",
    "        quarters.append(q)\n",
    "        last_date = q_start - timedelta(days=1)\n",
    "    return quarters[::-1]\n",
    "\n",
    "def compute_day_of_quarter(date_val):\n",
    "    if pd.isnull(date_val):\n",
    "        return pd.Series({'Day_of_Quarter': np.nan, \n",
    "                          'Total_Days_in_Quarter': np.nan, \n",
    "                          'Pct_Day': np.nan})\n",
    "    quarter, q_start, q_end = get_quarter_info(date_val)\n",
    "    day_of_quarter = (date_val - q_start).days + 1\n",
    "    total_days = (q_end - q_start).days + 1\n",
    "    pct_day = day_of_quarter / total_days * 100\n",
    "    return pd.Series({'Day_of_Quarter': day_of_quarter, \n",
    "                      'Total_Days_in_Quarter': total_days, \n",
    "                      'Pct_Day': pct_day})\n",
    "\n",
    "def compute_cumulative_raw(df_in):\n",
    "    grouped = df_in.groupby(['Quarter', 'Pct_Day_Bin'])['ARR Change'].sum().reset_index()\n",
    "    pivot = grouped.pivot(index='Pct_Day_Bin', columns='Quarter', values='ARR Change').fillna(0)\n",
    "    full_index = pd.Index(range(0, 101), name='Pct_Day_Bin')\n",
    "    pivot = pivot.reindex(full_index, fill_value=0)\n",
    "    cum = pivot.cumsum()\n",
    "    return cum\n",
    "\n",
    "\n",
    "def compute_cumulative_raw_pipegen(df_in):\n",
    "    # For Pipegen: group by Pipegen_Quarter and Pipegen_Pct_Day_Bin using ARR Change\n",
    "    grouped = df_in.groupby(['Pipegen_Quarter', 'Pipegen_Pct_Day_Bin'])['ARR Change'].sum().reset_index()\n",
    "    pivot = grouped.pivot(index='Pipegen_Pct_Day_Bin', columns='Pipegen_Quarter', values='ARR Change').fillna(0)\n",
    "    full_index = pd.Index(range(0, 101), name='Pipegen_Pct_Day_Bin')\n",
    "    pivot = pivot.reindex(full_index, fill_value=0)\n",
    "    cum = pivot.cumsum()\n",
    "    return cum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e761e3c9-b47f-4484-930d-41df716367a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:42:09.494401Z",
     "iopub.status.busy": "2025-07-17T18:42:09.494292Z",
     "iopub.status.idle": "2025-07-17T18:42:23.718976Z",
     "shell.execute_reply": "2025-07-17T18:42:23.718642Z",
     "shell.execute_reply.started": "2025-07-17T18:42:09.494391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assume you have loaded your SFDC report into a DataFrame called df\n",
    "# For example: df = pd.read_csv(\"sfdc_report.csv\")\n",
    "\n",
    "# List of date columns to enhance\n",
    "date_columns = ['Created Date', 'SQO Date', 'SAO Date', 'Timestamp: Solution Validation', 'Close Date']\n",
    "\n",
    "# Convert each to datetime\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Process each date column and merge the breakdown back into df\n",
    "for col in date_columns:\n",
    "    # Apply the breakdown function to the column\n",
    "    breakdown_df = df[col].apply(breakdown_date)\n",
    "    # Rename the resulting columns to include the original column name as prefix\n",
    "    breakdown_df = breakdown_df.rename(columns={\n",
    "        'Quarter': f'{col}_Quarter',\n",
    "        'Week_of_Quarter': f'{col}_Week_of_Quarter',\n",
    "        'Month': f'{col}_Month',\n",
    "        'Day_of_Week': f'{col}_Day_of_Week',\n",
    "        'Day_Name': f'{col}_Day_Name'\n",
    "    })\n",
    "    # Concatenate the breakdown info back into the main DataFrame\n",
    "    df = pd.concat([df, breakdown_df], axis=1)\n",
    "\n",
    "# At this point, df contains your original columns plus the breakdowns for each date field.\n",
    "# You can then save your master report:\n",
    "df.to_csv(\"master_report.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12cc0249-a894-4950-b0c1-c7d1dc622779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:42:23.719740Z",
     "iopub.status.busy": "2025-07-17T18:42:23.719642Z",
     "iopub.status.idle": "2025-07-17T18:43:28.024056Z",
     "shell.execute_reply": "2025-07-17T18:43:28.023323Z",
     "shell.execute_reply.started": "2025-07-17T18:42:23.719730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/1076719585.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/1076719585.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_to_update = data_to_update.applymap(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1A6Q8dvoWwLi26tnQQoEo6ZnekvZBQbpgCyP20iQV6Ug',\n",
       " 'updatedRange': 'Data!A1:BH35128',\n",
       " 'updatedRows': 35128,\n",
       " 'updatedColumns': 60,\n",
       " 'updatedCells': 1838597}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Get your worksheet\n",
    "worksheet = sht1.worksheet(\"Data\")\n",
    "\n",
    "# 0) Clear the existing sheet so you start fresh\n",
    "worksheet.clear()\n",
    "\n",
    "# 2) Copy your DataFrame\n",
    "data_to_update = df.copy()\n",
    "\n",
    "# 3) Ensure headers are strings\n",
    "data_to_update.columns = data_to_update.columns.astype(str)\n",
    "\n",
    "# 4) Trim all whitespace from strings\n",
    "data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# 5) Turn any “only‐spaces” cell into an empty string\n",
    "data_to_update = data_to_update.replace(r'^\\s*$', '', regex=True)\n",
    "\n",
    "# 6) Convert Timestamps to YYYY-MM-DD\n",
    "data_to_update = data_to_update.applymap(\n",
    "    lambda x: x.strftime('%Y-%m-%d') if isinstance(x, pd.Timestamp) else x\n",
    ")\n",
    "\n",
    "# 7) Replace NaN, ±inf with empty string\n",
    "data_to_update = data_to_update.fillna('').replace([np.inf, -np.inf], '')\n",
    "\n",
    "# 8) Build the list of lists, but map '' → None so Google Sheets sees a true blank\n",
    "headers = data_to_update.columns.tolist()\n",
    "rows = data_to_update.values.tolist()\n",
    "values = [headers]\n",
    "for row in rows:\n",
    "    clean_row = [None if (isinstance(cell, str) and cell == '') else cell for cell in row]\n",
    "    values.append(clean_row)\n",
    "\n",
    "# 9) Update the sheet\n",
    "worksheet.update(values, 'A1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49101f28-ccc6-4949-b174-f35dd4e23fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:43:28.027810Z",
     "iopub.status.busy": "2025-07-17T18:43:28.027519Z",
     "iopub.status.idle": "2025-07-17T18:43:28.128812Z",
     "shell.execute_reply": "2025-07-17T18:43:28.128482Z",
     "shell.execute_reply.started": "2025-07-17T18:43:28.027797Z"
    }
   },
   "outputs": [],
   "source": [
    "#SQLs# --- \n",
    "#1) GET THE LAST 5 QUARTERS (4 completed + active) ---\n",
    "today = datetime.today()\n",
    "active_quarter = get_quarter_info(today)[0]\n",
    "last_4 = get_last_completed_quarters(4, today)\n",
    "quarters_5 = last_4 + [active_quarter]\n",
    "\n",
    "# --- 2) SLIM DOWN YOUR DATAFRAME ---\n",
    "df_pivot = df[[\n",
    "    'Created Date_Quarter',\n",
    "    'Source',\n",
    "    'Segment - historical',\n",
    "    'Bookings Type'\n",
    "]].copy()\n",
    "\n",
    "# Map any non-standard source into \"Other\"\n",
    "allowed_src = ['AE','BDR','Channel','Marketing','Success']\n",
    "df_pivot['Source'] = df_pivot['Source'].where(df_pivot['Source'].isin(allowed_src), 'Other')\n",
    "\n",
    "# Filter to exactly the segments & booking types you want\n",
    "allowed_segs  = ['Enterprise','Mid Market','SMB']\n",
    "allowed_types = ['Expansion','New Business']\n",
    "df_pivot = df_pivot[\n",
    "    df_pivot['Segment - historical'].isin(allowed_segs) &\n",
    "    df_pivot['Bookings Type'].isin(allowed_types)\n",
    "]\n",
    "\n",
    "# --- 3) BUILD A STATIC ROW INDEX ---\n",
    "rows = []\n",
    "for src in ['AE','BDR','Channel','Marketing']:\n",
    "    for seg in allowed_segs:\n",
    "        for bt in allowed_types:\n",
    "            rows.append((src, seg, bt))\n",
    "        rows.append((src, seg, f'{seg} Total'))\n",
    "    rows.append((src, '', f'{src} Total'))\n",
    "\n",
    "rows.append(('Other','','Other Total'))\n",
    "\n",
    "for seg in allowed_segs:\n",
    "    for bt in allowed_types:\n",
    "        rows.append(('Success', seg, bt))\n",
    "    rows.append(('Success', seg, f'{seg} Total'))\n",
    "rows.append(('Success','','Success Total'))\n",
    "\n",
    "rows.append(('','','Grand Total'))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(\n",
    "    rows,\n",
    "    names=['Source','Segment - historical','Bookings Type']\n",
    ")\n",
    "\n",
    "# --- 4) INIT PIVOT SHELL ---\n",
    "pivot = pd.DataFrame(\n",
    "    0,\n",
    "    index=index,\n",
    "    columns=quarters_5 + ['Grand Total']\n",
    ")\n",
    "\n",
    "# --- 5) FILL THE DETAIL COUNTS ---\n",
    "grp = df_pivot.groupby(\n",
    "    ['Source','Segment - historical','Bookings Type','Created Date_Quarter']\n",
    ").size()\n",
    "\n",
    "for (src, seg, bt, q), cnt in grp.items():\n",
    "    if (src,seg,bt) in pivot.index and q in quarters_5:\n",
    "        pivot.at[(src,seg,bt), q] = cnt\n",
    "\n",
    "# --- 6) SEGMENT SUBTOTALS ---\n",
    "grp_seg = df_pivot.groupby(\n",
    "    ['Source','Segment - historical','Created Date_Quarter']\n",
    ").size()\n",
    "\n",
    "for (src, seg, q), cnt in grp_seg.items():\n",
    "    row = (src, seg, f'{seg} Total')\n",
    "    if row in pivot.index and q in quarters_5:\n",
    "        pivot.at[row, q] = cnt\n",
    "\n",
    "# --- 7) SOURCE SUBTOTALS ---\n",
    "grp_src = df_pivot.groupby(['Source','Created Date_Quarter']).size()\n",
    "for (src, q), cnt in grp_src.items():\n",
    "    row = (src, '', f'{src} Total')\n",
    "    if row in pivot.index and q in quarters_5:\n",
    "        pivot.at[row, q] = cnt\n",
    "\n",
    "# --- 8) GRAND TOTAL PER QUARTER ---\n",
    "grp_all = df_pivot.groupby('Created Date_Quarter').size()\n",
    "for q, cnt in grp_all.items():\n",
    "    if q in quarters_5:\n",
    "        pivot.at[('', '', 'Grand Total'), q] = cnt\n",
    "\n",
    "# --- 9) FINAL GRAND TOTAL COLUMN ---\n",
    "pivot['Grand Total'] = pivot[quarters_5].sum(axis=1)\n",
    "\n",
    "# --- 10) RESET INDEX FOR EXPORT / DISPLAY ---\n",
    "pivot_display = pivot.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3968b619-4183-49de-ad16-e390162ed86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:43:28.129358Z",
     "iopub.status.busy": "2025-07-17T18:43:28.129272Z",
     "iopub.status.idle": "2025-07-17T18:44:11.417092Z",
     "shell.execute_reply": "2025-07-17T18:44:11.415827Z",
     "shell.execute_reply.started": "2025-07-17T18:43:28.129348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2774254129.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2774254129.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_to_update = data_to_update.applymap(\n",
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2774254129.py:33: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet.update('B5', values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1A6Q8dvoWwLi26tnQQoEo6ZnekvZBQbpgCyP20iQV6Ug',\n",
       " 'updatedRange': 'SQLs!B5:J57',\n",
       " 'updatedRows': 53,\n",
       " 'updatedColumns': 9,\n",
       " 'updatedCells': 469}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1) Get your worksheet\n",
    "worksheet = sht1.worksheet(\"SQLs\")\n",
    "\n",
    "# 2) Prepare the DataFrame you want to push\n",
    "data_to_update = pivot_display.copy()  # pivot_display from the previous step\n",
    "\n",
    "# 3) Ensure headers are strings\n",
    "data_to_update.columns = data_to_update.columns.astype(str)\n",
    "\n",
    "# 4) Trim all whitespace from strings\n",
    "data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# 5) Turn any “only‐spaces” cell into an empty string\n",
    "data_to_update = data_to_update.replace(r'^\\s*$', '', regex=True)\n",
    "\n",
    "# 6) Convert any Timestamps to YYYY-MM-DD\n",
    "data_to_update = data_to_update.applymap(\n",
    "    lambda x: x.strftime('%Y-%m-%d') if hasattr(x, 'strftime') else x\n",
    ")\n",
    "\n",
    "# 7) Replace NaN, ±inf with empty string\n",
    "data_to_update = data_to_update.fillna('').replace([np.inf, -np.inf], '')\n",
    "\n",
    "# 8) Build the list of lists, mapping '' → None so Sheets sees true blanks\n",
    "headers = data_to_update.columns.tolist()\n",
    "rows    = data_to_update.values.tolist()\n",
    "values  = [headers]\n",
    "for row in rows:\n",
    "    clean = [None if (isinstance(c, str) and c=='') else c for c in row]\n",
    "    values.append(clean)\n",
    "\n",
    "# 9) Update the sheet at B5 (will expand to the right and down)\n",
    "worksheet.update('B5', values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abb5b7c-16aa-4976-b1fa-7cf408d94855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:44:11.421066Z",
     "iopub.status.busy": "2025-07-17T18:44:11.418983Z",
     "iopub.status.idle": "2025-07-17T18:44:54.198961Z",
     "shell.execute_reply": "2025-07-17T18:44:54.197931Z",
     "shell.execute_reply.started": "2025-07-17T18:44:11.421035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2049992231.py:101: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x,str) else x)\n",
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2049992231.py:110: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet_sao.update('B5', values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1A6Q8dvoWwLi26tnQQoEo6ZnekvZBQbpgCyP20iQV6Ug',\n",
       " 'updatedRange': 'SAOs!B5:J57',\n",
       " 'updatedRows': 53,\n",
       " 'updatedColumns': 9,\n",
       " 'updatedCells': 469}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 2) SLIMDF FOR SAO PIVOT ---\n",
    "df_sao = df[[\n",
    "    'SAO Date',\n",
    "    'SAO Date_Quarter',\n",
    "    'Source',\n",
    "    'Segment - historical',\n",
    "    'Bookings Type'\n",
    "]].copy()\n",
    "\n",
    "# Only keep rows that actually have an SAO date\n",
    "df_sao = df_sao[df_sao['SAO Date'].notna()]\n",
    "\n",
    "# Map “Other” sources\n",
    "allowed_src = ['AE','BDR','Channel','Marketing','Success']\n",
    "df_sao['Source'] = df_sao['Source'].where(df_sao['Source'].isin(allowed_src), 'Other')\n",
    "\n",
    "# Filter segments & types\n",
    "allowed_segs  = ['Enterprise','Mid Market','SMB']\n",
    "allowed_types = ['Expansion','New Business']\n",
    "df_sao = df_sao[\n",
    "    df_sao['Segment - historical'].isin(allowed_segs) &\n",
    "    df_sao['Bookings Type'].isin(allowed_types)\n",
    "]\n",
    "\n",
    "# --- 3) STATIC ROW LAYOUT (same as before) ---\n",
    "rows = []\n",
    "for src in ['AE','BDR','Channel','Marketing']:\n",
    "    for seg in allowed_segs:\n",
    "        for bt in allowed_types:\n",
    "            rows.append((src, seg, bt))\n",
    "        rows.append((src, seg, f'{seg} Total'))\n",
    "    rows.append((src, '', f'{src} Total'))\n",
    "\n",
    "rows.append(('Other','','Other Total'))\n",
    "\n",
    "for seg in allowed_segs:\n",
    "    for bt in allowed_types:\n",
    "        rows.append(('Success', seg, bt))\n",
    "    rows.append(('Success', seg, f'{seg} Total'))\n",
    "rows.append(('Success','','Success Total'))\n",
    "\n",
    "rows.append(('','','Grand Total'))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(\n",
    "    rows,\n",
    "    names=['Source','Segment - historical','Bookings Type']\n",
    ")\n",
    "\n",
    "# --- 4) INIT PIVOT SHELL ---\n",
    "pivot_sao = pd.DataFrame(\n",
    "    0,\n",
    "    index=index,\n",
    "    columns=quarters_5 + ['Grand Total']\n",
    ")\n",
    "\n",
    "# --- 5) DETAIL COUNTS BY SAO Date Quarter ---\n",
    "grp = df_sao.groupby(\n",
    "    ['Source','Segment - historical','Bookings Type','SAO Date_Quarter']\n",
    ").size()\n",
    "\n",
    "for (src, seg, bt, q), cnt in grp.items():\n",
    "    if (src,seg,bt) in pivot_sao.index and q in quarters_5:\n",
    "        pivot_sao.at[(src,seg,bt), q] = cnt\n",
    "\n",
    "# --- 6) SEGMENT SUBTOTALS ---\n",
    "grp_seg = df_sao.groupby(\n",
    "    ['Source','Segment - historical','SAO Date_Quarter']\n",
    ").size()\n",
    "\n",
    "for (src, seg, q), cnt in grp_seg.items():\n",
    "    row = (src, seg, f'{seg} Total')\n",
    "    if row in pivot_sao.index and q in quarters_5:\n",
    "        pivot_sao.at[row, q] = cnt\n",
    "\n",
    "# --- 7) SOURCE SUBTOTALS ---\n",
    "grp_src = df_sao.groupby(['Source','SAO Date_Quarter']).size()\n",
    "\n",
    "for (src, q), cnt in grp_src.items():\n",
    "    row = (src, '', f'{src} Total')\n",
    "    if row in pivot_sao.index and q in quarters_5:\n",
    "        pivot_sao.at[row, q] = cnt\n",
    "\n",
    "# --- 8) GRAND TOTAL PER QUARTER ---\n",
    "grp_all = df_sao.groupby('SAO Date_Quarter').size()\n",
    "for q, cnt in grp_all.items():\n",
    "    if q in quarters_5:\n",
    "        pivot_sao.at[('', '', 'Grand Total'), q] = cnt\n",
    "\n",
    "# --- 9) FINAL GRAND TOTAL COLUMN ---\n",
    "pivot_sao['Grand Total'] = pivot_sao[quarters_5].sum(axis=1)\n",
    "\n",
    "# --- 10) RESET FOR EXPORT ---\n",
    "pivot_sao_display = pivot_sao.reset_index()\n",
    "\n",
    "# --- 11) PUSH TO GOOGLE SHEETS at B5 in \"SAOs\" ---\n",
    "worksheet_sao = sht1.worksheet(\"SAOs\")\n",
    "\n",
    "# Prepare values (map ''→None for true blanks)\n",
    "data_to_update = pivot_sao_display.copy()\n",
    "data_to_update.columns = data_to_update.columns.astype(str)\n",
    "data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x,str) else x)\n",
    "data_to_update = data_to_update.replace(r'^\\s*$', '', regex=True)\n",
    "data_to_update = data_to_update.fillna('').replace([np.inf, -np.inf], '')\n",
    "headers = data_to_update.columns.tolist()\n",
    "rows = data_to_update.values.tolist()\n",
    "values = [headers]\n",
    "for row in rows:\n",
    "    values.append([None if (isinstance(c,str) and c=='') else c for c in row])\n",
    "\n",
    "worksheet_sao.update('B5', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f399eda0-f303-496a-a304-360fd1dcbc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:44:54.201703Z",
     "iopub.status.busy": "2025-07-17T18:44:54.200775Z",
     "iopub.status.idle": "2025-07-17T18:44:58.661331Z",
     "shell.execute_reply": "2025-07-17T18:44:58.660269Z",
     "shell.execute_reply.started": "2025-07-17T18:44:54.201662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2869846744.py:102: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x,str) else x)\n",
      "/var/folders/89/mmk3x71s01g09b0bf8137yrw0000gp/T/ipykernel_86043/2869846744.py:111: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet_pip.update('B5', values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1A6Q8dvoWwLi26tnQQoEo6ZnekvZBQbpgCyP20iQV6Ug',\n",
       " 'updatedRange': 'Pipegen!B5:J57',\n",
       " 'updatedRows': 53,\n",
       " 'updatedColumns': 9,\n",
       " 'updatedCells': 469}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 2) SLIMDF FOR SAO PIPGEN ---\n",
    "df_pip = df[[\n",
    "    'SAO Date_Quarter',\n",
    "    'Source',\n",
    "    'Segment - historical',\n",
    "    'Bookings Type',\n",
    "    'ARR Change'\n",
    "]].copy()\n",
    "\n",
    "# Only keep rows with an SAO\n",
    "df_pip = df_pip[df_pip['SAO Date_Quarter'].notna()]\n",
    "\n",
    "# Map non-standard sources into “Other”\n",
    "allowed_src = ['AE','BDR','Channel','Marketing','Success']\n",
    "df_pip['Source'] = df_pip['Source'].where(\n",
    "    df_pip['Source'].isin(allowed_src), 'Other'\n",
    ")\n",
    "\n",
    "# Filter segments & booking types\n",
    "allowed_segs  = ['Enterprise','Mid Market','SMB']\n",
    "allowed_types = ['Expansion','New Business']\n",
    "df_pip = df_pip[\n",
    "    df_pip['Segment - historical'].isin(allowed_segs) &\n",
    "    df_pip['Bookings Type'].isin(allowed_types)\n",
    "]\n",
    "\n",
    "# --- 3) STATIC ROW INDEX (same as before) ---\n",
    "rows = []\n",
    "for src in ['AE','BDR','Channel','Marketing']:\n",
    "    for seg in allowed_segs:\n",
    "        for bt in allowed_types:\n",
    "            rows.append((src, seg, bt))\n",
    "        rows.append((src, seg, f'{seg} Total'))\n",
    "    rows.append((src, '', f'{src} Total'))\n",
    "\n",
    "rows.append(('Other','','Other Total'))\n",
    "\n",
    "for seg in allowed_segs:\n",
    "    for bt in allowed_types:\n",
    "        rows.append(('Success', seg, bt))\n",
    "    rows.append(('Success', seg, f'{seg} Total'))\n",
    "rows.append(('Success','','Success Total'))\n",
    "\n",
    "rows.append(('','','Grand Total'))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(\n",
    "    rows,\n",
    "    names=['Source','Segment - historical','Bookings Type']\n",
    ")\n",
    "\n",
    "# --- 4) INIT PIVOT SHELL ---\n",
    "pivot_pip = pd.DataFrame(\n",
    "    0.0,\n",
    "    index=index,\n",
    "    columns=quarters_5 + ['Grand Total']\n",
    ")\n",
    "\n",
    "# --- 5) DETAIL: sum ARR Change by SAO Date_Quarter ---\n",
    "grp = df_pip.groupby(\n",
    "    ['Source','Segment - historical','Bookings Type','SAO Date_Quarter']\n",
    ")['ARR Change'].sum()\n",
    "\n",
    "for (src, seg, bt, q), total in grp.items():\n",
    "    if (src,seg,bt) in pivot_pip.index and q in quarters_5:\n",
    "        pivot_pip.at[(src,seg,bt), q] = total\n",
    "\n",
    "# --- 6) SEGMENT SUBTOTALS (sum ARR Change) ---\n",
    "grp_seg = df_pip.groupby(\n",
    "    ['Source','Segment - historical','SAO Date_Quarter']\n",
    ")['ARR Change'].sum()\n",
    "\n",
    "for (src, seg, q), total in grp_seg.items():\n",
    "    row = (src, seg, f'{seg} Total')\n",
    "    if row in pivot_pip.index and q in quarters_5:\n",
    "        pivot_pip.at[row, q] = total\n",
    "\n",
    "# --- 7) SOURCE SUBTOTALS ---\n",
    "grp_src = df_pip.groupby(['Source','SAO Date_Quarter'])['ARR Change'].sum()\n",
    "for (src, q), total in grp_src.items():\n",
    "    row = (src, '', f'{src} Total')\n",
    "    if row in pivot_pip.index and q in quarters_5:\n",
    "        pivot_pip.at[row, q] = total\n",
    "\n",
    "# --- 8) GRAND TOTAL PER QUARTER ---\n",
    "grp_all = df_pip.groupby('SAO Date_Quarter')['ARR Change'].sum()\n",
    "for q, total in grp_all.items():\n",
    "    if q in quarters_5:\n",
    "        pivot_pip.at[('', '', 'Grand Total'), q] = total\n",
    "\n",
    "# --- 9) GRAND TOTAL COLUMN ---\n",
    "pivot_pip['Grand Total'] = pivot_pip[quarters_5].sum(axis=1)\n",
    "\n",
    "# --- 10) RESET INDEX FOR EXPORT ---\n",
    "pivot_pip_display = pivot_pip.reset_index()\n",
    "\n",
    "# --- 11) PUSH INTO GOOGLE SHEETS AT B5 on sheet \"SAO_Pipgen\" ---\n",
    "worksheet_pip = sht1.worksheet(\"Pipegen\")\n",
    "\n",
    "# Clean & prepare values\n",
    "data_to_update = pivot_pip_display.copy()\n",
    "data_to_update.columns = data_to_update.columns.astype(str)\n",
    "data_to_update = data_to_update.applymap(lambda x: x.strip() if isinstance(x,str) else x)\n",
    "data_to_update = data_to_update.replace(r'^\\s*$', '', regex=True)\n",
    "data_to_update = data_to_update.fillna('').replace([np.inf, -np.inf], '')\n",
    "headers = data_to_update.columns.tolist()\n",
    "rows    = data_to_update.values.tolist()\n",
    "values  = [headers]\n",
    "for row in rows:\n",
    "    values.append([None if (isinstance(c,str) and c=='') else c for c in row])\n",
    "\n",
    "worksheet_pip.update('B5', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b09e50-74ed-46d8-b2bf-9b20064b7b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T18:44:58.662872Z",
     "iopub.status.busy": "2025-07-17T18:44:58.662587Z",
     "iopub.status.idle": "2025-07-17T18:44:58.672550Z",
     "shell.execute_reply": "2025-07-17T18:44:58.668920Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.662842Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1412344556.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    BreakBreakBreak production\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "BreakBreakBreak production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2e50c-613d-4dd4-9dc1-f771a850ded4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d25b17-8282-4092-b8b0-922610e8c084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b44aa5-3ee1-430b-9d6a-3e9615fd842c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ee1db-469b-48a8-9ced-44c7d028b451",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.672904Z",
     "iopub.status.idle": "2025-07-17T18:44:58.673047Z",
     "shell.execute_reply": "2025-07-17T18:44:58.672985Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.672976Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Assumes you already have:\n",
    "# df, df_pipegen, get_quarter_info(), get_last_completed_quarters(), etc.\n",
    "\n",
    "today = datetime.today()\n",
    "active_quarter = get_quarter_info(today)[0]\n",
    "last_4 = get_last_completed_quarters(4, today)\n",
    "quarters_5 = last_4 + [active_quarter]\n",
    "\n",
    "# 1) BOOKINGS METRICS\n",
    "bk = df[df['Stage']=='Closed Won'].copy()\n",
    "bk = bk[bk['Close Date_Quarter'].isin(quarters_5)]\n",
    "bookings_summary = (\n",
    "    bk.groupby(['Close Date_Quarter','Segment - historical'])\n",
    "      .agg(\n",
    "        bookings_arr=('ARR Change','sum'),\n",
    "        deals_closed=('SFDC ID 18 Digit','nunique'),\n",
    "        avg_deal_size=('ARR Change','mean')\n",
    "      )\n",
    "      .rename_axis(['Quarter','Segment'])\n",
    "      .reset_index()\n",
    ")\n",
    "bookings_wide = bookings_summary.pivot(\n",
    "    index='Segment', columns='Quarter',\n",
    "    values=['bookings_arr','deals_closed','avg_deal_size']\n",
    ").fillna(0)\n",
    "bookings_wide.columns = ['_'.join(col) for col in bookings_wide.columns]\n",
    "bookings_wide.reset_index(inplace=True)\n",
    "\n",
    "# 2) PIPEGEN METRICS\n",
    "pg = df[df['SAO Date_Quarter'].notna()].copy()\n",
    "pg = pg[pg['SAO Date_Quarter'].isin(quarters_5)]\n",
    "pipegen_summary = (\n",
    "    pg.groupby(['SAO Date_Quarter','Segment - historical'])\n",
    "      .agg(pipegen_arr=('ARR Change','sum'))\n",
    "      .rename_axis(['Quarter','Segment'])\n",
    "      .reset_index()\n",
    ")\n",
    "pipegen_wide = pipegen_summary.pivot(\n",
    "    index='Segment', columns='Quarter', values='pipegen_arr'\n",
    ").fillna(0)\n",
    "pipegen_wide.columns = [f'pipegen_arr_{q}' for q in pipegen_wide.columns]\n",
    "pipegen_wide.reset_index(inplace=True)\n",
    "\n",
    "# 3) COMBINE\n",
    "master = bookings_wide.merge(pipegen_wide, on='Segment', how='outer').fillna(0)\n",
    "\n",
    "# 4) SAFER QoQ & YoY FUNCTION\n",
    "def add_pct_changes(df, metric_prefix, quarters):\n",
    "    # Quarter-over-Quarter\n",
    "    for i in range(1, len(quarters)):\n",
    "        prev, curr = quarters[i-1], quarters[i]\n",
    "        c_prev, c_curr = f\"{metric_prefix}_{prev}\", f\"{metric_prefix}_{curr}\"\n",
    "        if c_prev in df.columns and c_curr in df.columns:\n",
    "            df[f\"{metric_prefix}_QoQ_{prev}_to_{curr}\"] = (\n",
    "                (df[c_curr] - df[c_prev]) / df[c_prev].replace(0, np.nan)\n",
    "            ) * 100\n",
    "    # Year-over-Year (compare first vs last)\n",
    "    yoy_prev, yoy_curr = quarters[0], quarters[-1]\n",
    "    c_prev, c_curr = f\"{metric_prefix}_{yoy_prev}\", f\"{metric_prefix}_{yoy_curr}\"\n",
    "    if c_prev in df.columns and c_curr in df.columns:\n",
    "        df[f\"{metric_prefix}_YoY_{yoy_prev}_to_{yoy_curr}\"] = (\n",
    "            (df[c_curr] - df[c_prev]) / df[c_prev].replace(0, np.nan)\n",
    "        ) * 100\n",
    "\n",
    "# 5) APPLY CHANGES\n",
    "add_pct_changes(master, \"bookings_arr\", quarters_5)\n",
    "add_pct_changes(master, \"pipegen_arr\", quarters_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac28544-5c1d-410b-8dcb-1bbbde699b74",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.673887Z",
     "iopub.status.idle": "2025-07-17T18:44:58.674013Z",
     "shell.execute_reply": "2025-07-17T18:44:58.673955Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.673949Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_last_completed_quarters(n, today=None):\n",
    "    \"\"\"\n",
    "    Returns a list of the last n completed quarters (as strings) based on the custom fiscal calendar.\n",
    "    For example, if today is 03/06/2025 (current quarter = \"2026-Q1\"), the most recent completed quarter\n",
    "    is \"2025-Q4\".\n",
    "    \"\"\"\n",
    "    if today is None:\n",
    "        today = datetime.today()\n",
    "    # Determine the current quarter (which is in progress)\n",
    "    current_quarter, q_start, q_end = get_quarter_info(today)\n",
    "    # Last completed quarter: one day before current quarter starts.\n",
    "    last_date = q_start - timedelta(days=1)\n",
    "    quarters = []\n",
    "    for _ in range(n):\n",
    "        q, q_start, q_end = get_quarter_info(last_date)\n",
    "        quarters.append(q)\n",
    "        last_date = q_start - timedelta(days=1)\n",
    "    # Reverse to show them in chronological order (oldest left, newest right)\n",
    "    return quarters[::-1]\n",
    "\n",
    "# ---------------------------\n",
    "# Define dynamic parameters and filter the data\n",
    "# ---------------------------\n",
    "# Set \"today\" dynamically\n",
    "today = datetime.today()\n",
    "last_5_quarters = get_last_completed_quarters(5, today)\n",
    "print(\"Last 5 completed quarters:\", last_5_quarters)\n",
    "\n",
    "# Define the three valid segments\n",
    "valid_segments = ['Enterprise', 'Mid Market', 'SMB']\n",
    "\n",
    "# Filter the master DataFrame for the segments of interest\n",
    "df_filtered = df[df['Segment - historical'].isin(valid_segments)]\n",
    "\n",
    "# For bookings, we only want opportunities with Stage = \"Closed Won\"\n",
    "df_bookings = df_filtered[df_filtered['Stage'] == 'Closed Won']\n",
    "\n",
    "# Ensure that the \"Close Date_Quarter\" column exists.\n",
    "# If it doesn’t, create it using get_quarter_info on the \"Close Date\" column.\n",
    "if 'Close Date_Quarter' not in df_bookings.columns:\n",
    "    def get_close_quarter(date_val):\n",
    "        if pd.isnull(date_val):\n",
    "            return None\n",
    "        q, _, _ = get_quarter_info(date_val)\n",
    "        return q\n",
    "    df_bookings['Close Date_Quarter'] = df_bookings['Close Date'].apply(get_close_quarter)\n",
    "\n",
    "# Now, filter df_bookings to only include rows from the last 5 completed quarters\n",
    "df_bookings = df_bookings[df_bookings['Close Date_Quarter'].isin(last_5_quarters)]\n",
    "\n",
    "# ---------------------------\n",
    "# View 1: Bookings by Quarter (by Segment)\n",
    "# ---------------------------\n",
    "view1 = pd.pivot_table(\n",
    "    df_bookings,\n",
    "    index='Segment - historical',\n",
    "    columns='Close Date_Quarter',\n",
    "    values='ARR Change',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "# Reorder columns to match last_5_quarters\n",
    "view1 = view1.reindex(columns=last_5_quarters)\n",
    "# Add a \"Total\" row that sums each quarter\n",
    "view1.loc['Total'] = view1.sum()\n",
    "\n",
    "# ---------------------------\n",
    "# View 2: Bookings Type Breakdown (Gross and %)\n",
    "# ---------------------------\n",
    "# Pivot table with rows = Bookings Type, columns = Close Date_Quarter, values = sum of ARR Change\n",
    "view2_gross = pd.pivot_table(\n",
    "    df_bookings,\n",
    "    index='Bookings Type',\n",
    "    columns='Close Date_Quarter',\n",
    "    values='ARR Change',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "view2_gross = view2_gross.reindex(columns=last_5_quarters)\n",
    "\n",
    "# Create a percentage view (each quarter column sums to 100)\n",
    "view2_pct = view2_gross.div(view2_gross.sum(axis=0), axis=1) * 100\n",
    "view2_pct = view2_pct.round(2)\n",
    "\n",
    "# ---------------------------\n",
    "# View 3: Bookings Type by Segment (Gross and %)\n",
    "# ---------------------------\n",
    "# Pivot table with a multi-index: rows = [Segment, Bookings Type], columns = Close Date_Quarter\n",
    "view3_gross = pd.pivot_table(\n",
    "    df_bookings,\n",
    "    index=['Segment - historical', 'Bookings Type'],\n",
    "    columns='Close Date_Quarter',\n",
    "    values='ARR Change',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "view3_gross = view3_gross.reindex(columns=last_5_quarters)\n",
    "\n",
    "# Create a percentage view.\n",
    "# For each segment, for each quarter column, calculate the percentage breakdown by Bookings Type.\n",
    "view3_pct = view3_gross.copy()\n",
    "for seg in view3_pct.index.get_level_values(0).unique():\n",
    "    idx = view3_pct.index.get_level_values(0) == seg\n",
    "    view3_pct.loc[idx] = view3_pct.loc[idx].div(view3_pct.loc[idx].sum(), axis=1) * 100\n",
    "view3_pct = view3_pct.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3bc6c-80fe-42d2-897e-88bc6b406866",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.674531Z",
     "iopub.status.idle": "2025-07-17T18:44:58.674669Z",
     "shell.execute_reply": "2025-07-17T18:44:58.674595Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.674589Z"
    }
   },
   "outputs": [],
   "source": [
    "view1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f31ec3-5a61-4d42-aa75-b36d26b53083",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.675277Z",
     "iopub.status.idle": "2025-07-17T18:44:58.675508Z",
     "shell.execute_reply": "2025-07-17T18:44:58.675440Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.675434Z"
    }
   },
   "outputs": [],
   "source": [
    "view2_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b000fe-c031-4a37-8005-ca3812f39919",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.676146Z",
     "iopub.status.idle": "2025-07-17T18:44:58.676261Z",
     "shell.execute_reply": "2025-07-17T18:44:58.676208Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.676203Z"
    }
   },
   "outputs": [],
   "source": [
    "view2_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba2271-99c3-4f80-9abc-42d8f89d98c9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.676695Z",
     "iopub.status.idle": "2025-07-17T18:44:58.676882Z",
     "shell.execute_reply": "2025-07-17T18:44:58.676775Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.676769Z"
    }
   },
   "outputs": [],
   "source": [
    "view3_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf6d62-ddef-45c4-b2b0-0bc4c48dc3df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.677365Z",
     "iopub.status.idle": "2025-07-17T18:44:58.677514Z",
     "shell.execute_reply": "2025-07-17T18:44:58.677449Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.677443Z"
    }
   },
   "outputs": [],
   "source": [
    "view3_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e66493-9a4f-4f69-a885-37683d71fcb5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.678340Z",
     "iopub.status.idle": "2025-07-17T18:44:58.678759Z",
     "shell.execute_reply": "2025-07-17T18:44:58.678666Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.678660Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Data Preparation\n",
    "# ---------------------------\n",
    "# Assume your SFDC report is in DataFrame \"df\" with date fields processed.\n",
    "# Filter for bookings (Stage = \"Closed Won\")\n",
    "df_bookings = df[df['Stage'] == 'Closed Won'].copy()\n",
    "df_bookings[['Day_of_Quarter','Total_Days_in_Quarter','Pct_Day']] = df_bookings['Close Date'].apply(compute_day_of_quarter)\n",
    "df_bookings['Pct_Day_Bin'] = df_bookings['Pct_Day'].round(0)\n",
    "df_bookings['Quarter'] = df_bookings['Close Date'].apply(lambda x: get_quarter_info(x)[0] if pd.notnull(x) else None)\n",
    "\n",
    "today = datetime.today()\n",
    "active_quarter, active_q_start, active_q_end = get_quarter_info(today)\n",
    "today_pct_bin = round(compute_day_of_quarter(today)[\"Pct_Day\"])\n",
    "\n",
    "# For same quarter comparisons, define quarters for past 2 years\n",
    "year_current = int(active_quarter.split('-')[0])\n",
    "q_part = active_quarter.split('-')[1]\n",
    "quarter_last_year = f\"{year_current - 1}-{q_part}\"\n",
    "quarter_two_years_ago = f\"{year_current - 2}-{q_part}\"\n",
    "\n",
    "# Fixed color mapping for same-quarter comparisons (View 2 & 4)\n",
    "fixed_colors = {\n",
    "    quarter_two_years_ago: \"#1f77b4\",  # blue\n",
    "    quarter_last_year: \"#2ca02c\",       # green\n",
    "    active_quarter: \"#d62728\"           # red (current quarter)\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# View 1: Company-wide – Current Quarter vs. Historical Average (Last 8 Completed Quarters)\n",
    "# ---------------------------\n",
    "last_8_quarters = get_last_completed_quarters(8, today)\n",
    "view1_quarters = last_8_quarters + [active_quarter]\n",
    "df_view1 = df_bookings[df_bookings['Quarter'].isin(view1_quarters)].copy()\n",
    "cum_view1_raw = compute_cumulative_raw(df_view1)\n",
    "hist_cols = [q for q in last_8_quarters if q in cum_view1_raw.columns]\n",
    "current_col = active_quarter if active_quarter in cum_view1_raw.columns else None\n",
    "\n",
    "historical_avg_curve = cum_view1_raw[hist_cols].mean(axis=1)\n",
    "target_value_view1 = historical_avg_curve.loc[100]\n",
    "historical_avg_pacing = (historical_avg_curve / target_value_view1) * 100\n",
    "if current_col is not None:\n",
    "    current_cum = cum_view1_raw[current_col]\n",
    "    current_pacing = (current_cum / target_value_view1) * 100\n",
    "else:\n",
    "    current_pacing = pd.Series([np.nan]*101, index=range(0,101))\n",
    "current_pacing_truncated = current_pacing[current_pacing.index <= today_pct_bin]\n",
    "\n",
    "df_view1_pacing = pd.DataFrame({\n",
    "    'Pct_Day_Bin': range(0, 101),\n",
    "    'Historical Avg Pacing (%)': historical_avg_pacing,\n",
    "    'Current Quarter Pacing (%)': current_pacing\n",
    "}).set_index('Pct_Day_Bin')\n",
    "\n",
    "fig_view1 = go.Figure()\n",
    "fig_view1.add_trace(go.Scatter(x=historical_avg_pacing.index, y=historical_avg_pacing.values,\n",
    "                               mode='lines+markers', name='Historical Avg',\n",
    "                               line=dict(color=\"#1f77b4\")))  # blue\n",
    "fig_view1.add_trace(go.Scatter(x=current_pacing_truncated.index, y=current_pacing_truncated.values,\n",
    "                               mode='lines+markers', name='Current Quarter',\n",
    "                               line=dict(color=\"#d62728\")))  # red\n",
    "fig_view1.update_layout(title='Company-wide Bookings Pacing: Current Quarter vs. Historical Average (Last 8 Quarters)',\n",
    "                        xaxis_title='% of Quarter Completed',\n",
    "                        yaxis_title='Pacing',\n",
    "                        yaxis_range=[0, 105],\n",
    "                        autosize=False, width=1600, height=960)\n",
    "fig_view1.show()\n",
    "\n",
    "print(\"View 1 Data (Company-wide):\")\n",
    "print(df_view1_pacing)\n",
    "\n",
    "# ---------------------------\n",
    "# View 2: Company-wide – Current Quarter vs. Same Quarter (Past 2 Years)\n",
    "# ---------------------------\n",
    "view2_quarters = [quarter_two_years_ago, quarter_last_year, active_quarter]\n",
    "df_view2 = df_bookings[df_bookings['Quarter'].isin(view2_quarters)].copy()\n",
    "cum_view2_raw = compute_cumulative_raw(df_view2)\n",
    "df_view2_pct = pd.DataFrame(index=range(0,101))\n",
    "for q in view2_quarters:\n",
    "    if q not in cum_view2_raw.columns:\n",
    "        continue\n",
    "    if q == active_quarter:\n",
    "        if (quarter_last_year in cum_view2_raw.columns) and (quarter_two_years_ago in cum_view2_raw.columns):\n",
    "            target_active = np.mean([cum_view2_raw[quarter_last_year].iloc[100],\n",
    "                                      cum_view2_raw[quarter_two_years_ago].iloc[100]])\n",
    "        else:\n",
    "            target_active = np.nan\n",
    "        series = cum_view2_raw[q].copy()\n",
    "        pacing_series = series.apply(lambda x: (x / target_active)*100 if pd.notnull(x) and target_active > 0 else np.nan)\n",
    "        pacing_current = pacing_series[pacing_series.index <= today_pct_bin]\n",
    "        df_view2_pct[q] = pacing_current\n",
    "    else:\n",
    "        target_q = cum_view2_raw[q].iloc[100]\n",
    "        series = cum_view2_raw[q].copy()\n",
    "        pacing_series = series.apply(lambda x: (x / target_q)*100 if pd.notnull(x) and target_q > 0 else np.nan)\n",
    "        df_view2_pct[q] = pacing_series\n",
    "\n",
    "fig_view2 = go.Figure()\n",
    "for q in view2_quarters:\n",
    "    if q not in df_view2_pct.columns:\n",
    "        continue\n",
    "    series = df_view2_pct[q].dropna()\n",
    "    fig_view2.add_trace(go.Scatter(x=series.index, y=series.values,\n",
    "                                   mode='lines+markers', name=f'{q}',\n",
    "                                   line=dict(color=fixed_colors.get(q, \"#000000\"))))\n",
    "fig_view2.update_layout(title='Company-wide Bookings Pacing: Current Quarter vs. Same Quarter (Past 2 Years)',\n",
    "                        xaxis_title='% of Quarter Completed',\n",
    "                        yaxis_title='Pacing',\n",
    "                        yaxis_range=[0, 105],\n",
    "                        autosize=False, width=1600, height=960)\n",
    "fig_view2.show()\n",
    "\n",
    "print(\"View 2 Data (Company-wide):\")\n",
    "print(df_view2_pct)\n",
    "\n",
    "# ---------------------------\n",
    "# View 3: Segment-Specific – Current Quarter vs. Historical Average (Last 8 Completed Quarters)\n",
    "# ---------------------------\n",
    "segments = ['SMB', 'Mid Market', 'Enterprise']\n",
    "for seg in segments:\n",
    "    df_seg = df_bookings[df_bookings['Segment - historical'] == seg].copy()\n",
    "    if df_seg.empty:\n",
    "        print(f\"No data for segment: {seg}\")\n",
    "        continue\n",
    "    \n",
    "    df_seg_view1 = df_seg[df_seg['Quarter'].isin(view1_quarters)].copy()\n",
    "    cum_seg_raw = compute_cumulative_raw(df_seg_view1)\n",
    "    \n",
    "    seg_hist_cols = [q for q in last_8_quarters if q in cum_seg_raw.columns]\n",
    "    seg_current_col = active_quarter if active_quarter in cum_seg_raw.columns else None\n",
    "    if len(seg_hist_cols) == 0 or seg_current_col is None:\n",
    "        print(f\"Insufficient data for segment: {seg}\")\n",
    "        continue\n",
    "    \n",
    "    seg_historical_avg_curve = cum_seg_raw[seg_hist_cols].mean(axis=1)\n",
    "    seg_target_value = seg_historical_avg_curve.loc[100]\n",
    "    seg_historical_avg_pacing = (seg_historical_avg_curve / seg_target_value) * 100\n",
    "    seg_current_pacing = (cum_seg_raw[active_quarter] / seg_target_value) * 100\n",
    "    seg_current_pacing_truncated = seg_current_pacing[seg_current_pacing.index <= today_pct_bin]\n",
    "    \n",
    "    fig_seg = go.Figure()\n",
    "    fig_seg.add_trace(go.Scatter(x=seg_historical_avg_pacing.index,\n",
    "                                 y=seg_historical_avg_pacing.values,\n",
    "                                 mode='lines+markers',\n",
    "                                 name='Historical Avg',\n",
    "                                 line=dict(color=\"#1f77b4\")))\n",
    "    fig_seg.add_trace(go.Scatter(x=seg_current_pacing_truncated.index,\n",
    "                                 y=seg_current_pacing_truncated.values,\n",
    "                                 mode='lines+markers',\n",
    "                                 name='Current Quarter',\n",
    "                                 line=dict(color=\"#d62728\")))\n",
    "    fig_seg.update_layout(title=f'{seg} Bookings Pacing: Current Quarter vs. Historical Average (Last 8 Quarters)',\n",
    "                          xaxis_title='% of Quarter Completed',\n",
    "                          yaxis_title='Pacing',\n",
    "                          yaxis_range=[0,105],\n",
    "                          autosize=False, width=1600, height=960)\n",
    "    fig_seg.show()\n",
    "    file_path = os.path.join('master', f'bookings_{seg}_view3.png')\n",
    "    fig_seg.write_image(file_path)\n",
    "    \n",
    "    seg_pacing_df = pd.DataFrame({\n",
    "        'Historical Avg Pacing (%)': seg_historical_avg_pacing,\n",
    "        'Current Quarter Pacing (%)': seg_current_pacing\n",
    "    }).set_index(seg_historical_avg_pacing.index)\n",
    "    print(f\"{seg} Historical vs. Current Pacing Data:\")\n",
    "    print(seg_pacing_df)\n",
    "\n",
    "# ---------------------------\n",
    "# View 4: Segment-Specific – Current vs. Same Quarter (Past 2 Years)\n",
    "# ---------------------------\n",
    "for seg in ['SMB', 'Mid Market', 'Enterprise']:\n",
    "    df_seg = df_bookings[df_bookings['Segment - historical'] == seg].copy()\n",
    "    if df_seg.empty:\n",
    "        print(f\"No data for segment: {seg}\")\n",
    "        continue\n",
    "    df_seg_view2 = df_seg[df_seg['Quarter'].isin(view2_quarters)].copy()\n",
    "    cum_seg_view2_raw = compute_cumulative_raw(df_seg_view2)\n",
    "    df_seg_view2_pct = pd.DataFrame(index=range(0,101))\n",
    "    for q in view2_quarters:\n",
    "        if q not in cum_seg_view2_raw.columns:\n",
    "            continue\n",
    "        if q == active_quarter:\n",
    "            if (quarter_last_year in cum_seg_view2_raw.columns) and (quarter_two_years_ago in cum_seg_view2_raw.columns):\n",
    "                target_active = np.mean([cum_seg_view2_raw[quarter_last_year].iloc[100],\n",
    "                                          cum_seg_view2_raw[quarter_two_years_ago].iloc[100]])\n",
    "            else:\n",
    "                target_active = np.nan\n",
    "            series = cum_seg_view2_raw[q].copy()\n",
    "            pacing_series = series.apply(lambda x: (x / target_active)*100 if pd.notnull(x) and target_active > 0 else np.nan)\n",
    "            pacing_current = pacing_series[pacing_series.index <= today_pct_bin]\n",
    "            df_seg_view2_pct[q] = pacing_current\n",
    "        else:\n",
    "            target_q = cum_seg_view2_raw[q].iloc[100]\n",
    "            series = cum_seg_view2_raw[q].copy()\n",
    "            pacing_series = series.apply(lambda x: (x / target_q)*100 if pd.notnull(x) and target_q > 0 else np.nan)\n",
    "            df_seg_view2_pct[q] = pacing_series\n",
    "    fig_seg2 = go.Figure()\n",
    "    for q in view2_quarters:\n",
    "        if q not in df_seg_view2_pct.columns:\n",
    "            continue\n",
    "        series = df_seg_view2_pct[q].dropna()\n",
    "        fig_seg2.add_trace(go.Scatter(\n",
    "            x=series.index,\n",
    "            y=series.values,\n",
    "            mode='lines+markers',\n",
    "            name=f'{q}',\n",
    "            line=dict(color=fixed_colors.get(q, \"#000000\"))\n",
    "        ))\n",
    "    fig_seg2.update_layout(title=f'{seg} Bookings Pacing: Current vs. Same Quarter (Past 2 Years)',\n",
    "                           xaxis_title='% of Quarter Completed',\n",
    "                           yaxis_title='Pacing',\n",
    "                           yaxis_range=[0,105],\n",
    "                           autosize=False, width=1600, height=960)\n",
    "    fig_seg2.show()\n",
    "    file_path = os.path.join('master', f'bookings_{seg}_view4.png')\n",
    "    fig_seg2.write_image(file_path)\n",
    "    print(f\"Segment {seg} Pacing Data (Same Quarter Comparison):\")\n",
    "    print(df_seg_view2_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74438234-f308-4a7f-a081-029b371f44ed",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.679496Z",
     "iopub.status.idle": "2025-07-17T18:44:58.679644Z",
     "shell.execute_reply": "2025-07-17T18:44:58.679548Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.679542Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Preprocess Pipegen Data (based on SAO Date)\n",
    "# ---------------------------\n",
    "df_pipegen = df[df['SAO Date'].notnull()].copy()\n",
    "df_pipegen['SAO Date'] = pd.to_datetime(df_pipegen['SAO Date'], errors='coerce')\n",
    "df_pipegen[['Pipegen_Day_of_Quarter','Pipegen_Total_Days_in_Quarter','Pipegen_Pct_Day']] = df_pipegen['SAO Date'].apply(compute_day_of_quarter)\n",
    "df_pipegen['Pipegen_Pct_Day_Bin'] = df_pipegen['Pipegen_Pct_Day'].round(0)\n",
    "df_pipegen['Pipegen_Quarter'] = df_pipegen['SAO Date'].apply(lambda x: get_quarter_info(x)[0] if pd.notnull(x) else None)\n",
    "\n",
    "today = datetime.today()\n",
    "active_pipegen_quarter, active_pipegen_q_start, active_pipegen_q_end = get_quarter_info(today)\n",
    "pipegen_today_pct_bin = round(compute_day_of_quarter(today)[\"Pct_Day\"])\n",
    "\n",
    "# Define last 8 completed quarters and same-quarter comparisons for Pipegen\n",
    "last_8_quarters_pipegen = get_last_completed_quarters(8, today)\n",
    "view1_quarters_pipegen = last_8_quarters_pipegen + [active_pipegen_quarter]\n",
    "\n",
    "year_current = int(active_pipegen_quarter.split('-')[0])\n",
    "q_part = active_pipegen_quarter.split('-')[1]\n",
    "quarter_last_year = f\"{year_current - 1}-{q_part}\"\n",
    "quarter_two_years_ago = f\"{year_current - 2}-{q_part}\"\n",
    "view2_quarters_pipegen = [quarter_two_years_ago, quarter_last_year, active_pipegen_quarter]\n",
    "\n",
    "# ---------------------------\n",
    "# Remove unwanted Sources (\"Other\" and \"Connect\")\n",
    "# ---------------------------\n",
    "all_sources_pipegen = df_pipegen['Source'].unique()\n",
    "sources_pipegen = [s for s in all_sources_pipegen if s not in ['Other', 'Connect']]\n",
    "\n",
    "# ---------------------------\n",
    "# Fixed color mapping for same-quarter comparisons (View 2 & 4)\n",
    "# ---------------------------\n",
    "fixed_colors = {\n",
    "    quarter_two_years_ago: \"#1f77b4\",  # blue\n",
    "    quarter_last_year: \"#2ca02c\",       # green\n",
    "    active_pipegen_quarter: \"#d62728\"   # red (current quarter)\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Ensure the 'master' folder exists for saving charts\n",
    "# ---------------------------\n",
    "CHARTS_DIR = 'master'\n",
    "os.makedirs(CHARTS_DIR, exist_ok=True)\n",
    "\n",
    "# ===========================\n",
    "# PIPEGEN VIEW 1: Company-wide – Current Quarter vs. Historical Average (Last 8 Quarters)\n",
    "# (One chart per Source)\n",
    "# ===========================\n",
    "for src in sources_pipegen:\n",
    "    df_src = df_pipegen[df_pipegen['Source'] == src].copy()\n",
    "    df_src_view1 = df_src[df_src['Pipegen_Quarter'].isin(view1_quarters_pipegen)].copy()\n",
    "    cum_src_raw = compute_cumulative_raw_pipegen(df_src_view1)\n",
    "    hist_cols_src = [q for q in last_8_quarters_pipegen if q in cum_src_raw.columns]\n",
    "    current_col_src = active_pipegen_quarter if active_pipegen_quarter in cum_src_raw.columns else None\n",
    "    if len(hist_cols_src) == 0 or current_col_src is None:\n",
    "        continue\n",
    "    historical_avg_curve_src = cum_src_raw[hist_cols_src].mean(axis=1)\n",
    "    target_value_src = historical_avg_curve_src.loc[100]\n",
    "    historical_avg_pacing_src = (historical_avg_curve_src / target_value_src) * 100\n",
    "    current_cum_src = cum_src_raw[current_col_src]\n",
    "    current_pacing_src = (current_cum_src / target_value_src) * 100\n",
    "    current_pacing_src_truncated = current_pacing_src[current_pacing_src.index <= pipegen_today_pct_bin]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "         x=historical_avg_pacing_src.index,\n",
    "         y=historical_avg_pacing_src.values,\n",
    "         mode='lines+markers',\n",
    "         name=f'Historical Avg - {src}',\n",
    "         line=dict(color=\"#1f77b4\")\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "         x=current_pacing_src_truncated.index,\n",
    "         y=current_pacing_src_truncated.values,\n",
    "         mode='lines+markers',\n",
    "         name=f'Current Quarter - {src}',\n",
    "         line=dict(color=\"#d62728\")\n",
    "    ))\n",
    "    fig.update_layout(title=f'Pipegen: {src} – Current vs. Historical Average (Last 8 Quarters)',\n",
    "                      xaxis_title='% of Quarter Completed',\n",
    "                      yaxis_title='Pacing',\n",
    "                      yaxis_range=[0,105],\n",
    "                      autosize=False, width=1600, height=960)\n",
    "    fig.show()\n",
    "    file_path = os.path.join(CHARTS_DIR, f'pipegen_{src}_view1.png')\n",
    "    fig.write_image(file_path)\n",
    "\n",
    "# ===========================\n",
    "# PIPEGEN VIEW 2: Company-wide – Current Quarter vs. Same Quarter (Past 2 Years)\n",
    "# (One chart per Source; fixed colors used for the three quarters)\n",
    "# ===========================\n",
    "for src in sources_pipegen:\n",
    "    df_src = df_pipegen[df_pipegen['Source'] == src].copy()\n",
    "    df_src_view2 = df_src[df_src['Pipegen_Quarter'].isin(view2_quarters_pipegen)].copy()\n",
    "    cum_src_raw = compute_cumulative_raw_pipegen(df_src_view2)\n",
    "    df_src_pct = pd.DataFrame(index=range(0,101))\n",
    "    for q in view2_quarters_pipegen:\n",
    "        if q not in cum_src_raw.columns:\n",
    "            continue\n",
    "        if q == active_pipegen_quarter:\n",
    "            if (quarter_last_year in cum_src_raw.columns) and (quarter_two_years_ago in cum_src_raw.columns):\n",
    "                target_active = np.mean([cum_src_raw[quarter_last_year].iloc[100],\n",
    "                                          cum_src_raw[quarter_two_years_ago].iloc[100]])\n",
    "            else:\n",
    "                target_active = np.nan\n",
    "            series = cum_src_raw[q].copy()\n",
    "            pacing_series = series.apply(lambda x: (x / target_active)*100 if pd.notnull(x) and target_active > 0 else np.nan)\n",
    "            pacing_current = pacing_series[pacing_series.index <= pipegen_today_pct_bin]\n",
    "            df_src_pct[q] = pacing_current\n",
    "        else:\n",
    "            target_q = cum_src_raw[q].iloc[100]\n",
    "            series = cum_src_raw[q].copy()\n",
    "            pacing_series = series.apply(lambda x: (x / target_q)*100 if pd.notnull(x) and target_q > 0 else np.nan)\n",
    "            df_src_pct[q] = pacing_series\n",
    "    fig = go.Figure()\n",
    "    for q in view2_quarters_pipegen:\n",
    "        if q not in df_src_pct.columns:\n",
    "            continue\n",
    "        series = df_src_pct[q].dropna()\n",
    "        fig.add_trace(go.Scatter(\n",
    "             x=series.index,\n",
    "             y=series.values,\n",
    "             mode='lines+markers',\n",
    "             name=f'{q}',\n",
    "             line=dict(color=fixed_colors.get(q, \"#000000\"))\n",
    "        ))\n",
    "    fig.update_layout(title=f'Pipegen: {src} – Current vs. Same Quarter (Past 2 Years)',\n",
    "                      xaxis_title='% of Quarter Completed',\n",
    "                      yaxis_title='Pacing',\n",
    "                      yaxis_range=[0,105],\n",
    "                      autosize=False, width=1600, height=960)\n",
    "    fig.show()\n",
    "    file_path = os.path.join(CHARTS_DIR, f'pipegen_{src}_view2.png')\n",
    "    fig.write_image(file_path)\n",
    "\n",
    "# ===========================\n",
    "# PIPEGEN VIEW 3: Segment-Specific – Current Quarter vs. Historical Average (Last 8 Quarters)\n",
    "# (One chart per Segment per Source)\n",
    "# ===========================\n",
    "for seg in ['SMB', 'Mid Market', 'Enterprise']:\n",
    "    df_seg = df_pipegen[df_pipegen['Segment - historical'] == seg].copy()\n",
    "    if df_seg.empty:\n",
    "        print(f\"No pipegen data for segment: {seg}\")\n",
    "        continue\n",
    "    sources_seg = [s for s in df_seg['Source'].unique() if s not in ['Other', 'Connect']]\n",
    "    for src in sources_seg:\n",
    "        df_seg_src = df_seg[df_seg['Source'] == src].copy()\n",
    "        df_seg_src_view1 = df_seg_src[df_seg_src['Pipegen_Quarter'].isin(view1_quarters_pipegen)].copy()\n",
    "        cum_seg_src_raw = compute_cumulative_raw_pipegen(df_seg_src_view1)\n",
    "        seg_hist_cols_src = [q for q in last_8_quarters_pipegen if q in cum_seg_src_raw.columns]\n",
    "        seg_current_col_src = active_pipegen_quarter if active_pipegen_quarter in cum_seg_src_raw.columns else None\n",
    "        if len(seg_hist_cols_src) == 0 or seg_current_col_src is None:\n",
    "            continue\n",
    "        seg_historical_avg_curve = cum_seg_src_raw[seg_hist_cols_src].mean(axis=1)\n",
    "        seg_target_value = seg_historical_avg_curve.loc[100]\n",
    "        seg_historical_avg_pacing = (seg_historical_avg_curve / seg_target_value) * 100\n",
    "        seg_current_cum = cum_seg_src_raw[seg_current_col_src]\n",
    "        seg_current_pacing = (seg_current_cum / seg_target_value) * 100\n",
    "        seg_current_pacing_truncated = seg_current_pacing[seg_current_pacing.index <= pipegen_today_pct_bin]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "             x=seg_historical_avg_pacing.index,\n",
    "             y=seg_historical_avg_pacing.values,\n",
    "             mode='lines+markers',\n",
    "             name=f'Historical Avg - {src}',\n",
    "             line=dict(color=\"#1f77b4\")\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "             x=seg_current_pacing_truncated.index,\n",
    "             y=seg_current_pacing_truncated.values,\n",
    "             mode='lines+markers',\n",
    "             name=f'Current Quarter - {src}',\n",
    "             line=dict(color=\"#d62728\")\n",
    "        ))\n",
    "        fig.update_layout(title=f'Pipegen {seg}: {src} – Current vs. Historical Average (Last 8 Quarters)',\n",
    "                          xaxis_title='% of Quarter Completed',\n",
    "                          yaxis_title='Pacing',\n",
    "                          yaxis_range=[0,105],\n",
    "                          autosize=False, width=1600, height=960)\n",
    "        fig.show()\n",
    "        file_path = os.path.join(CHARTS_DIR, f'pipegen_{seg}_{src}_view3.png')\n",
    "        fig.write_image(file_path)\n",
    "\n",
    "# ===========================\n",
    "# PIPEGEN VIEW 4: Segment-Specific – Current Quarter vs. Same Quarter (Past 2 Years)\n",
    "# (One chart per Segment per Source)\n",
    "# ===========================\n",
    "for seg in ['SMB', 'Mid Market', 'Enterprise']:\n",
    "    df_seg = df_pipegen[df_pipegen['Segment - historical'] == seg].copy()\n",
    "    if df_seg.empty:\n",
    "        print(f\"No pipegen data for segment: {seg}\")\n",
    "        continue\n",
    "    sources_seg = [s for s in df_seg['Source'].unique() if s not in ['Other', 'Connect']]\n",
    "    for src in sources_seg:\n",
    "        df_seg_src = df_seg[df_seg['Source'] == src].copy()\n",
    "        df_seg_src_view2 = df_seg_src[df_seg_src['Pipegen_Quarter'].isin(view2_quarters_pipegen)].copy()\n",
    "        cum_seg_src_raw = compute_cumulative_raw_pipegen(df_seg_src_view2)\n",
    "        df_seg_src_pct = pd.DataFrame(index=range(0,101))\n",
    "        for q in view2_quarters_pipegen:\n",
    "            if q not in cum_seg_src_raw.columns:\n",
    "                continue\n",
    "            if q == active_pipegen_quarter:\n",
    "                if (quarter_last_year in cum_seg_src_raw.columns) and (quarter_two_years_ago in cum_seg_src_raw.columns):\n",
    "                    target_active_seg = np.mean([cum_seg_src_raw[quarter_last_year].iloc[100],\n",
    "                                                 cum_seg_src_raw[quarter_two_years_ago].iloc[100]])\n",
    "                else:\n",
    "                    target_active_seg = np.nan\n",
    "                series = cum_seg_src_raw[q].copy()\n",
    "                pacing_series = series.apply(lambda x: (x / target_active_seg)*100 if pd.notnull(x) and target_active_seg > 0 else np.nan)\n",
    "                pacing_current = pacing_series[pacing_series.index <= pipegen_today_pct_bin]\n",
    "                df_seg_src_pct[q] = pacing_current\n",
    "            else:\n",
    "                target_q = cum_seg_src_raw[q].iloc[100]\n",
    "                series = cum_seg_src_raw[q].copy()\n",
    "                pacing_series = series.apply(lambda x: (x / target_q)*100 if pd.notnull(x) and target_q > 0 else np.nan)\n",
    "                df_seg_src_pct[q] = pacing_series\n",
    "        fig = go.Figure()\n",
    "        for q in view2_quarters_pipegen:\n",
    "            if q not in df_seg_src_pct.columns:\n",
    "                continue\n",
    "            series = df_seg_src_pct[q].dropna()\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=series.index,\n",
    "                y=series.values,\n",
    "                mode='lines+markers',\n",
    "                name=f'{q}',\n",
    "                line=dict(color=fixed_colors.get(q, \"#000000\"))\n",
    "            ))\n",
    "        fig.update_layout(title=f'Pipegen {seg}: {src} – Current vs. Same Quarter (Past 2 Years)',\n",
    "                          xaxis_title='% of Quarter Completed',\n",
    "                          yaxis_title='Pacing',\n",
    "                          yaxis_range=[0,105],\n",
    "                          autosize=False, width=1600, height=960)\n",
    "        fig.show()\n",
    "        file_path = os.path.join(CHARTS_DIR, f'pipegen_{seg}_{src}_view4.png')\n",
    "        fig.write_image(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de11a66-0050-4dec-a4f4-3192b9ccf223",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.680397Z",
     "iopub.status.idle": "2025-07-17T18:44:58.680507Z",
     "shell.execute_reply": "2025-07-17T18:44:58.680451Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.680446Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Assumptions:\n",
    "# df_pipegen is your preprocessed DataFrame for Pipegen (based on SAO Date)\n",
    "# It contains at least: 'Pipegen_Quarter', 'Source', and 'ARR Change'\n",
    "# active_pipegen_quarter is defined (e.g., via get_quarter_info(today)[0])\n",
    "# get_last_completed_quarters(n, today) is available.\n",
    "\n",
    "today = datetime.today()\n",
    "\n",
    "# Define last 8 completed quarters and include the current quarter\n",
    "last_8_quarters_pipegen = get_last_completed_quarters(8, today)\n",
    "quarters_to_include = last_8_quarters_pipegen + [active_pipegen_quarter]\n",
    "\n",
    "# Filter the Pipegen DataFrame for these quarters\n",
    "df_pipegen_filtered = df_pipegen[df_pipegen['Pipegen_Quarter'].isin(quarters_to_include)].copy()\n",
    "\n",
    "# Group by Pipegen_Quarter and Source, summing ARR Change\n",
    "grouped = df_pipegen_filtered.groupby(['Pipegen_Quarter', 'Source'])['ARR Change'].sum().reset_index()\n",
    "\n",
    "# Pivot so that rows = Pipegen_Quarter and columns = Source\n",
    "pivot = grouped.pivot(index='Pipegen_Quarter', columns='Source', values='ARR Change').fillna(0)\n",
    "\n",
    "# Enforce our desired chronological order using quarters_to_include\n",
    "pivot = pivot.reindex(quarters_to_include)\n",
    "\n",
    "# Pre-calculate the total ARR change per quarter for the absolute chart\n",
    "pivot_totals = pivot.sum(axis=1)\n",
    "\n",
    "# ---------------------------\n",
    "# Absolute Stacked Bar Chart (ARR Change in absolute terms)\n",
    "# ---------------------------\n",
    "fig_absolute = go.Figure()\n",
    "# For each source, create labels that are shown only if:\n",
    "#   - the value is >= 1,000 AND\n",
    "#   - that value is at least 5% of the quarter's total\n",
    "for source in pivot.columns:\n",
    "    labels = []\n",
    "    for q in pivot.index:\n",
    "        v = pivot.at[q, source]\n",
    "        total = pivot_totals.loc[q]\n",
    "        # Avoid division by zero:\n",
    "        if total == 0 or v < 1000 or (v / total * 100) < 5:\n",
    "            labels.append(\"\")\n",
    "        else:\n",
    "            labels.append(f'{v/1000:.1f}K')\n",
    "    fig_absolute.add_trace(go.Bar(\n",
    "         x=pivot.index,\n",
    "         y=pivot[source],\n",
    "         name=source,\n",
    "         text=labels,\n",
    "         textposition='auto',\n",
    "         textfont=dict(size=14)\n",
    "    ))\n",
    "fig_absolute.update_layout(\n",
    "    barmode='stack',\n",
    "    title='Pipegen Contributions by Source (Absolute ARR Change)',\n",
    "    xaxis_title='Quarter',\n",
    "    yaxis_title='ARR Change',\n",
    "    width=1600,\n",
    "    height=960\n",
    ")\n",
    "fig_absolute.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Normalized (100% Stacked) Bar Chart (Percentage contributions)\n",
    "# ---------------------------\n",
    "# Compute percentage contributions per quarter\n",
    "pivot_sum = pivot.sum(axis=1).replace(0, 1)  # avoid division by zero\n",
    "pivot_percent = pivot.div(pivot_sum, axis=0) * 100\n",
    "\n",
    "# Set threshold for showing data labels in normalized chart (only show if >= 5%)\n",
    "label_threshold = 2\n",
    "\n",
    "fig_normalized = go.Figure()\n",
    "for source in pivot_percent.columns:\n",
    "    labels = [f'{val:.1f}%' if val >= label_threshold else '' for val in pivot_percent[source].values]\n",
    "    fig_normalized.add_trace(go.Bar(\n",
    "         x=pivot_percent.index,\n",
    "         y=pivot_percent[source],\n",
    "         name=source,\n",
    "         text=labels,\n",
    "         textposition='inside',\n",
    "         textfont=dict(size=14)\n",
    "    ))\n",
    "fig_normalized.update_layout(\n",
    "    barmode='stack',\n",
    "    title='Pipegen Contributions by Source (Normalized to 100%)',\n",
    "    xaxis_title='Quarter',\n",
    "    yaxis_title='Percentage',\n",
    "    yaxis=dict(range=[0, 100], tickvals=list(range(0, 101, 10))),\n",
    "    width=1600,\n",
    "    height=960\n",
    ")\n",
    "fig_normalized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4242e90-cd60-4f23-bd20-efd739ffde5c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.681277Z",
     "iopub.status.idle": "2025-07-17T18:44:58.681396Z",
     "shell.execute_reply": "2025-07-17T18:44:58.681336Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.681331Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------\n",
    "# SAVE AGGREGATED PIPEGEN STACKED BAR CHARTS\n",
    "# ---------------------------\n",
    "abs_path_stack = os.path.join(CHARTS_DIR, 'pipegen_stacked_absolute.png')\n",
    "fig_absolute.write_image(abs_path_stack)\n",
    "\n",
    "norm_path_stack = os.path.join(CHARTS_DIR, 'pipegen_stacked_normalized.png')\n",
    "fig_normalized.write_image(norm_path_stack)\n",
    "\n",
    "print(\"All charts have been saved to the 'master' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a76ce-709a-4171-a5fd-ab1843dea0ac",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-17T18:44:58.682352Z",
     "iopub.status.idle": "2025-07-17T18:44:58.682454Z",
     "shell.execute_reply": "2025-07-17T18:44:58.682400Z",
     "shell.execute_reply.started": "2025-07-17T18:44:58.682395Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\n",
    "SPREADSHEET_ID = '1A6Q8dvoWwLi26tnQQoEo6ZnekvZBQbpgCyP20iQV6Ug'  # Replace with your spreadsheet ID\n",
    "SHEET_NAME = 'Charts'  # The sheet name where you want to put the charts\n",
    "CREDENTIALS_FILE = '/Users/bchen/Downloads/gspread-428120-06947c66447d.json'\n",
    "\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/spreadsheets',\n",
    "    'https://www.googleapis.com/auth/drive'\n",
    "]\n",
    "\n",
    "# Set the directory for charts to 'master'\n",
    "CHARTS_DIR = 'master'\n",
    "os.makedirs(CHARTS_DIR, exist_ok=True)\n",
    "# Get all PNG chart files from CHARTS_DIR\n",
    "chart_files = [os.path.join(CHARTS_DIR, f) for f in os.listdir(CHARTS_DIR) if f.lower().endswith('.png')]\n",
    "\n",
    "# ---------------------------\n",
    "# AUTHENTICATION\n",
    "# ---------------------------\n",
    "creds = Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=SCOPES)\n",
    "client = gspread.authorize(creds)\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)\n",
    "\n",
    "# ---------------------------\n",
    "# DRIVE UPLOAD FUNCTION\n",
    "# ---------------------------\n",
    "def upload_image_to_drive(local_path):\n",
    "    \"\"\"\n",
    "    Uploads a PNG image to Google Drive, makes it public, and returns its URL.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(local_path)\n",
    "    file_metadata = {'name': file_name, 'mimeType': 'image/png'}\n",
    "    media = MediaFileUpload(local_path, mimetype='image/png')\n",
    "    uploaded_file = drive_service.files().create(\n",
    "        body=file_metadata,\n",
    "        media_body=media,\n",
    "        fields='id'\n",
    "    ).execute()\n",
    "    file_id = uploaded_file.get('id')\n",
    "    # Make the file publicly accessible\n",
    "    drive_service.permissions().create(\n",
    "        fileId=file_id,\n",
    "        body={'type': 'anyone', 'role': 'reader'}\n",
    "    ).execute()\n",
    "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# ---------------------------\n",
    "# BUILD IMAGE FORMULAS FOR GOOGLE SHEETS\n",
    "# ---------------------------\n",
    "# For each chart image file, upload it and create an IMAGE formula.\n",
    "# The formula uses mode 4 (custom size) with height=800 and width=1600.\n",
    "rows = []\n",
    "for chart_path in chart_files:\n",
    "    image_url = upload_image_to_drive(chart_path)\n",
    "    # Build the IMAGE formula. Using value_input_option 'USER_ENTERED'\n",
    "    formula = f'=IMAGE(\"{image_url}\", 4, 960, 1600)'\n",
    "    rows.append([formula])\n",
    "\n",
    "# ---------------------------\n",
    "# UPDATE GOOGLE SHEET WITH THE IMAGE FORMULAS\n",
    "# ---------------------------\n",
    "# Using value_input_option='USER_ENTERED' so the formula is interpreted properly (without a leading apostrophe)\n",
    "\n",
    "sheet.clear()\n",
    "sheet.update(\"A1\", rows, value_input_option='USER_ENTERED')\n",
    "\n",
    "print(\"Successfully updated the Google Sheet with chart images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294fd08d-c61a-47c5-9de8-a9b92359b28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5598d-f99b-495b-95c6-cd44ec5c5cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1ac32-d13d-4e96-92bc-f21fa915a891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479ebc1-6b28-4408-8b52-e4dfc636a24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
